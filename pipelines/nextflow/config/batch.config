params {
    // The ID to use for Tracer's trace_id - default to a random UUID
    // that will be consistent across batch nodes - the user can override
    // this to use the run_id from tracer init/start.
    tracer_trace_id = java.util.UUID.randomUUID().toString()
    // S3 bucket for work directory - make configurable
    s3_work_bucket = 'tracer-nxf-work'
}

workDir = "s3://${params.s3_work_bucket}/work"

process {
    executor = 'awsbatch'
    queue = 'NextflowCPU'

    // Default resource requirements
    cpus = 1
    memory = '2 GB'
    time = '1h'

    // Set the env variables for the containers - using the trace ID
    containerOptions = "--env TRACER_TRACE_ID=${params.tracer_trace_id}"

    // Error handling
    errorStrategy = 'retry'
    maxRetries = 2

    resourceLabels = [
        'launch-time': new java.util.Date().format('yyyy-MM-dd_HH-mm-ss'),
        'custom-session-uuid': "${params.tracer_trace_id}",
        'project': 'tracer-bioinformatics'
    ]
}

aws {
    region = 'us-east-1'
    batch {
        cliPath = '/usr/local/aws-cli/v2/current/bin/aws'
        maxSpotAttempts = 5
        volumes = '/tmp'
    }

    // S3 client configuration
    client {
        maxConnections = 20
        connectionTimeout = 300000
        uploadStorageClass = 'INTELLIGENT_TIERING'
        storageEncryption = 'AES256'
        maxErrorRetry = 3
        socketTimeout = 300000
    }
}

// Enable detailed logging and monitoring
trace {
    enabled = true
    file = "s3://${params.s3_work_bucket}/logs/trace.txt"
    overwrite = true
}

report {
    enabled = true
    file = "s3://${params.s3_work_bucket}/logs/report.html"
    overwrite = true
}

timeline {
    enabled = true
    file = "s3://${params.s3_work_bucket}/logs/timeline.html"
    overwrite = true
}

// Cleanup configuration
cleanup = true

// Enable tower integration if available
tower {
    enabled = false
    endpoint = 'https://tower.nf'
}
